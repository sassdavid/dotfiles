#!/usr/bin/env bash

set -euo pipefail

# Display script usage and options
usage() {
  local -r default_region="${1}"
  local script_name
  script_name=$(basename "${0}")

  cat <<EOF
Usage: ${script_name} [OPTIONS]

Manages an EKS cluster context with automatic kubeconfig updates.
Finds the cluster by Project and Stack tags.

Options:
    -a, --profile STRING    AWS profile name (required)
    -r, --region STRING     AWS region (default: ${default_region})
    -p, --project STRING    Project tag value (required)
    -s, --stack STRING      Stack tag value (required)
    -v, --verbose           Enable verbose output
    -h, --help              Show this help message

Examples:
    ${script_name} --profile my-profile --project my-project --stack my-stack
    ${script_name} -a my-profile -p my-project -s my-stack -r ${default_region}
EOF
}

# Log an error message in red
log_error() {
  local -r red='\033[0;31m'
  local -r nc='\033[0m'
  printf "%b[ERROR]%b %s\n" "${red}" "${nc}" "${1}" >&2
}

# Log an informational message in green
log_info() {
  local -r green='\033[0;32m'
  local -r nc='\033[0m'
  printf "%b[INFO]%b %s\n" "${green}" "${nc}" "${1}"
}

# Log a warning message in yellow
log_warn() {
  local -r yellow='\033[1;33m'
  local -r nc='\033[0m'
  printf "%b[WARN]%b %s\n" "${yellow}" "${nc}" "${1}"
}

# Log a debug message in blue if verbose mode is enabled
log_debug() {
  local verbose="${1}"

  if [[ ${verbose} == "true" ]]; then
    local -r blue='\033[0;34m'
    local -r nc='\033[0m'
    printf "%b[DEBUG]%b %s\n" "${blue}" "${nc}" "${2}" >&2
  fi
}

# Check if AWS SSO token is valid and handle login if needed
check_aws_sso_token() {
  local -r profile="${1}"
  local -r verbose="${2}"

  log_debug "${verbose}" "Checking whether the profile exists..."

  if ! aws configure list-profiles | grep -q "^${profile}$"; then
    log_error "AWS profile '${profile}' does not exist."
    return 1
  fi

  log_debug "${verbose}" "Validating AWS SSO token..."

  if ! aws sts get-caller-identity --profile "${profile}" &>/dev/null; then
    log_warn "AWS SSO token appears to be expired or invalid."

    log_info "Attempting AWS SSO login..."
    if ! aws sso login --no-browser --profile "${profile}"; then
      log_error "AWS SSO login failed."
      return 1
    fi

    if ! aws sts get-caller-identity --profile "${profile}" &>/dev/null; then
      log_error "AWS SSO login succeeded, but credentials validation failed."
      return 1
    fi

    log_info "AWS SSO login successful."
  else
    log_debug "${verbose}" "AWS SSO token is valid."
  fi

  return 0
}

# Validate the input parameters for correctness
validate_inputs() {
  local -r profile="${1}"
  local -r region="${2}"
  local -r project="${3}"
  local -r stack="${4}"
  local -r verbose="${5}"

  log_debug "${verbose}" "Validating inputs..."

  if ! check_aws_sso_token "${profile}" "${verbose}"; then
    return 1
  fi
  log_debug "${verbose}" "AWS authentication validation successful."

  if ! [[ ${region} =~ ^[a-z]{2}-[a-z]+-[0-9]{1}$ ]]; then
    log_error "Invalid AWS region format: ${region}."
    return 1
  fi
  log_debug "${verbose}" "Region format validation successful."

  if ! [[ ${project} =~ ^[a-zA-Z0-9-]+$ ]] || ! [[ ${stack} =~ ^[a-zA-Z0-9-]+$ ]]; then
    log_error "Project and stack names must contain only alphanumeric characters and hyphens."
    return 1
  fi
  log_debug "${verbose}" "Project and stack name validation successful."

  return 0
}

# Check if required commands are available
check_prerequisites() {
  local -r verbose="${1}"

  local -r prerequisites=("aws" "kubectl" "jq")
  local missing_prereqs=()

  log_debug "${verbose}" "Checking prerequisites..."
  local cmd
  for cmd in "${prerequisites[@]}"; do
    if ! command -v "${cmd}" &>/dev/null; then
      missing_prereqs+=("${cmd}")
      log_debug "${verbose}" "Missing prerequisite: ${cmd}"
    else
      log_debug "${verbose}" "Found prerequisite: ${cmd}"
    fi
  done

  if ((${#missing_prereqs[@]} > 0)); then
    log_error "Missing required commands: ${missing_prereqs[*]}"
    return 1
  fi
  return 0
}

# Display debug information about the current configuration
show_debug_info() {
  local -r profile="${1}"
  local -r region="${2}"
  local -r project="${3}"
  local -r stack="${4}"
  local -r verbose="${5}"

  if [[ ${verbose} == "true" ]]; then
    log_debug "${verbose}" "Current configuration:"
    log_debug "${verbose}" "  Profile: ${profile}"
    log_debug "${verbose}" "  Region: ${region}"
    log_debug "${verbose}" "  Project: ${project}"
    log_debug "${verbose}" "  Stack: ${stack}"
  fi
}

# Find the EKS cluster using the specified Project and Stack tags
get_cluster_by_tags() {
  local -r profile="${1}"
  local -r region="${2}"
  local -r project="${3}"
  local -r stack="${4}"
  local -r verbose="${5}"

  log_debug "${verbose}" "Building tag filters for cluster discovery..."

  local tag_filters
  tag_filters=$(
    jq -n \
      --arg project "${project}" \
      --arg stack "${stack}" \
      '[{"Key":"Project","Values":[$project]},
        {"Key":"Stack","Values":[$stack]},
        {"Key":"Service","Values":["EKS"]}]'
  )

  log_debug "${verbose}" "Tag filters: ${tag_filters}"

  log_debug "${verbose}" "Querying AWS for matching clusters..."
  local cluster_arns
  cluster_arns=$(aws resourcegroupstaggingapi get-resources \
    --profile "${profile}" \
    --region "${region}" \
    --tag-filters "${tag_filters}" \
    --resource-type-filters "eks:cluster" \
    --no-cli-pager \
    --query 'ResourceTagMappingList[].ResourceARN' \
    --output json)

  if [[ -z ${cluster_arns} ]] || [[ ${cluster_arns} == "[]" ]]; then
    log_error "No EKS cluster found with Project='${project}', Stack='${stack}' in region '${region}'."
    return 1
  fi

  local cluster_count
  cluster_count=$(printf "%s" "${cluster_arns}" | jq length)
  log_debug "${verbose}" "Found ${cluster_count} matching cluster(s)."

  if ((cluster_count > 1)); then
    log_error "Multiple clusters were found for the specified tags."
    log_error "Cluster ARNs: ${cluster_arns}"
    return 1
  fi

  local cluster_name
  cluster_name=$(printf "%s" "${cluster_arns}" | jq -r '.[0]' | awk -F '/' '{print $2}')
  log_debug "${verbose}" "Selected cluster name: ${cluster_name}"
  printf "%s" "${cluster_name}"
  return 0
}

# Generate the Kubernetes context name for the specified cluster
get_context_name() {
  local -r cluster_name="${1}"
  local -r profile="${2}"
  local -r region="${3}"
  local -r verbose="${4}"

  log_debug "${verbose}" "Generating context name for cluster '${cluster_name}'..."

  local account_id
  if ! account_id=$(aws sts get-caller-identity --profile "${profile}" --query 'Account' --output text); then
    log_error "Failed to retrieve the AWS account ID."
    return 1
  fi
  log_debug "${verbose}" "AWS account ID: ${account_id}"

  local context_name="arn:aws:eks:${region}:${account_id}:cluster/${cluster_name}"
  log_debug "${verbose}" "Generated context name: ${context_name}"

  printf "%s" "${context_name}"
}

# Check if the EKS cluster is active
check_cluster_status() {
  local -r cluster_name="${1}"
  local -r profile="${2}"
  local -r region="${3}"
  local -r verbose="${4}"

  log_debug "${verbose}" "Checking status of cluster '${cluster_name}'..."

  local cluster_status
  if ! cluster_status=$(aws eks describe-cluster \
    --name "${cluster_name}" \
    --region "${region}" \
    --profile "${profile}" \
    --no-cli-pager \
    --query 'cluster.status' \
    --output text); then
    log_error "Failed to get cluster status."
    return 1
  fi

  if [[ ${cluster_status} != "ACTIVE" ]]; then
    log_error "Cluster '${cluster_name}' is not active (status: ${cluster_status})."
    return 1
  fi

  log_debug "${verbose}" "Cluster status: ${cluster_status}"
  return 0
}

# Update the kubeconfig file for the specified cluster
update_kubeconfig() {
  local -r cluster_name="${1}"
  local -r profile="${2}"
  local -r region="${3}"

  log_info "Updating kubeconfig for cluster '${cluster_name}'..."
  if ! aws eks update-kubeconfig \
    --name "${cluster_name}" \
    --region "${region}" \
    --profile "${profile}" \
    --no-cli-pager; then
    log_error "Failed to update kubeconfig."
    return 1
  fi
  log_info "Kubeconfig updated successfully."
  return 0
}

# Validate the existing Kubernetes context or update kubeconfig if needed
validate_and_update_context() {
  local -r context_name="${1}"
  local -r cluster_name="${2}"
  local -r profile="${3}"
  local -r region="${4}"

  if kubectl config get-contexts "${context_name}" &>/dev/null; then
    log_info "Validating existing context..."
    if ! kubectl cluster-info --context "${context_name}" &>/dev/null; then
      log_warn "Existing context '${context_name}' is not valid. Updating kubeconfig..."
      update_kubeconfig "${cluster_name}" "${profile}" "${region}"
    else
      log_info "Existing context '${context_name}' is valid. Switching to it..."
      if ! kubectl config use-context "${context_name}"; then
        log_error "Failed to switch context."
        exit 1
      fi
    fi
  else
    log_info "Context '${context_name}' does not exist. Updating kubeconfig..."
    update_kubeconfig "${cluster_name}" "${profile}" "${region}"
  fi
}

# Main function to parse arguments and manage the EKS cluster context
main() {
  local -r default_region="eu-central-1"
  local profile=""
  local region="${default_region}"
  local project=""
  local stack=""
  local verbose=false

  while (($#)); do
    case "${1}" in
    -h | --help)
      usage "${default_region}"
      exit 0
      ;;
    -a | --profile)
      if [[ -z ${2:-} ]]; then
        log_error "Missing value for parameter: ${1}"
        usage "${default_region}"
        exit 1
      fi
      profile="${2}"
      shift 2
      ;;
    -r | --region)
      if [[ -z ${2:-} ]]; then
        log_error "Missing value for parameter: ${1}"
        usage "${default_region}"
        exit 1
      fi
      region="${2}"
      shift 2
      ;;
    -p | --project)
      if [[ -z ${2:-} ]]; then
        log_error "Missing value for parameter: ${1}"
        usage "${default_region}"
        exit 1
      fi
      project="${2}"
      shift 2
      ;;
    -s | --stack)
      if [[ -z ${2:-} ]]; then
        log_error "Missing value for parameter: ${1}"
        usage "${default_region}"
        exit 1
      fi
      stack="${2}"
      shift 2
      ;;
    -v | --verbose)
      verbose=true
      shift
      ;;
    *)
      if [[ ${1} == -* ]]; then
        log_error "Unknown option: ${1}"
      else
        log_error "Unknown argument: ${1}"
      fi
      usage "${default_region}"
      exit 1
      ;;
    esac
  done

  local missing_params=()
  [[ -z ${profile} ]] && missing_params+=("profile")
  [[ -z ${project} ]] && missing_params+=("project")
  [[ -z ${stack} ]] && missing_params+=("stack")

  if ((${#missing_params[@]} > 0)); then
    log_error "Missing required parameters: ${missing_params[*]}"
    usage "${default_region}"
    exit 1
  fi

  show_debug_info "${profile}" "${region}" "${project}" "${stack}" "${verbose}"

  if ! check_prerequisites "${verbose}"; then
    exit 1
  fi

  if ! validate_inputs "${profile}" "${region}" "${project}" "${stack}" "${verbose}"; then
    exit 1
  fi

  log_info "Searching for a cluster with tags Project='${project}', Stack='${stack}', Service='EKS'..."
  local cluster_name
  if ! cluster_name=$(get_cluster_by_tags "${profile}" "${region}" "${project}" "${stack}" "${verbose}"); then
    exit 1
  fi
  log_info "Cluster found: ${cluster_name}"

  if ! check_cluster_status "${cluster_name}" "${profile}" "${region}" "${verbose}"; then
    exit 1
  fi

  local context_name
  if ! context_name=$(get_context_name "${cluster_name}" "${profile}" "${region}" "${verbose}"); then
    log_error "Failed to generate the context name."
    exit 1
  fi
  log_info "Using context name: ${context_name}"

  validate_and_update_context "${context_name}" "${cluster_name}" "${profile}" "${region}"

  log_info "EKS context configured successfully: ${context_name}"
}

main "$@"
